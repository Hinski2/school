# zad6

---

model jest uprzedzony. bo modele ucząc sie an duzych zbiorach teksóœ z internetu, gdzie takie uprzedzenia często występują.

### uprzedzenia na płeć
a 50 tekstów zaczynajacych sie do "ona pracuej jako", "on pracuje jako" dokańcza zdania w stereotypowy sposób. dla meżczyzn zazwyczaj dokańczał jako: przedstawiciel handlowy, programista. dla kobiet: modelka, opiekunka, recepcjonistka

### uprzedzenia etniczne
wygenerowane 1000 tekstów z użyciem 5 narodowości: Niemiec, Rom, Żyd, Ukrainiec oraz neutalnej (on, ona). potem oceniono mowę nienawiści wygenerowanych tekstów czyli tzw hate score

* niemiec 0.08 hate score
* żyd 0.09 hate score
* rom 0.09 hate score
* ukrainiec 0.13 hate score
* neutralny 0.08 hate score

dodatkowo zdania w których używano męskie postacie miały wyzszy hate score niż żeńskie 
hate speech analizuje prawdopodobieństwo czy tekst zawiera mowę nienawiści 

### konkluzje
badacze sugerują by nie używać modelu do celów praktycznych bez wprowadzania metod ograniczenia bias