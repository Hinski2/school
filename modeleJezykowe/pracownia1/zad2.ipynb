{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zad 2 Jakub Ilińki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "PAPUGA = 'flax-community/papuGaPT2'\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PAPUGA)\n",
    "model = AutoModelForCausalLM.from_pretrained(PAPUGA).to(DEVICE)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        self.prob = self.sentence_prob()\n",
    "    \n",
    "    @staticmethod \n",
    "    def log_probs_from_logits(logits, labels):\n",
    "        logp = F.log_softmax(logits, dim=-1)\n",
    "        logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "        return logp_label\n",
    "    \n",
    "    def sentence_prob(self):\n",
    "        input_ids = tokenizer(self.text, return_tensors='pt')['input_ids'].to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids)\n",
    "            log_probs = self.log_probs_from_logits(output.logits[:, :-1, :], input_ids[:, 1:])\n",
    "            # seq_log_probs = torch.mean(log_probs)\n",
    "            \n",
    "        return float(log_probs[:, -1])\n",
    "        \n",
    "    def print(self) -> None:\n",
    "        text = self.text  \n",
    "        text = text.capitalize()\n",
    "        text += '.'\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def generate_all_possible_sentences(text: str) -> List[str]: \n",
    "    words: List[str] = list(text.split())\n",
    "    return [\" \".join(p) for p in permutations(words)]\n",
    "\n",
    "def get_k_most_propable(sentences: List[Sentence], k: int) -> List[Sentence]:\n",
    "    sorted_sentences = sorted(sentences, key=lambda s: float(s.prob), reverse=True)\n",
    "    return sorted_sentences[:k]\n",
    "\n",
    "def get_k_least_propable(sentence: List[Sentence], k: int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rogate miała babuleńka dwa koziołki.\n",
      "Miała babuleńka dwa rogate koziołki.\n",
      "Rogate babuleńka miała dwa koziołki.\n",
      "Miała rogate babuleńka dwa koziołki.\n",
      "Miała babuleńka rogate dwa koziołki.\n",
      "\n",
      "W parku wiewiurki zaczepiają przechodniów.\n",
      "Parku w wiewiurki zaczepiają przechodniów.\n",
      "Wiewiurki zaczepiają w parku przechodniów.\n",
      "Parku zaczepiają w wiewiurki przechodniów.\n",
      "Zaczepiają w parku wiewiurki przechodniów.\n",
      "\n",
      "Kuba lubi ciastka.\n",
      "Kuba ciastka lubi.\n",
      "Ciastka kuba lubi.\n",
      "Ciastka lubi kuba.\n",
      "Lubi ciastka kuba.\n"
     ]
    }
   ],
   "source": [
    "strings = [\n",
    "    \"Babuleńka miała dwa rogate koziołki.\",\n",
    "    \"Wiewiurki w parku zaczepiają przechodniów.\",\n",
    "    \"Kuba lubi ciastka.\"\n",
    "]\n",
    "\n",
    "k = 5\n",
    "for string in strings: \n",
    "    print()\n",
    "    \n",
    "    all_sequences = [Sentence(s) for s in generate_all_possible_sentences(string)]\n",
    "    k_most_propable = get_k_most_propable(all_sequences, k)\n",
    "    k_least_propable = get_k_least_propable(all_sequences, k)\n",
    "    \n",
    "    for s in k_most_propable:\n",
    "        s.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
