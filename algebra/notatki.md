# rozdziaÅ‚ 1

---

### ciaÅ‚a
`def` - podstawowa struktura algebraicza w ktÃ³rej zdefiniowane sÄ… dwie operacje:
* dodawanie
* mnoÅ¼enie

przykÅ‚ady: 
* $\R$
* $\mathbb{Q}$

### przestrzenei liniowe 
`def` - zbiÃ³r wektorÃ³w, w kÃ³rym zdefiniowane sÄ… operacje dodawania wektorÃ³w i mnoÅ¼enia wektorÃ³w przez skalary. MoÅ¼na o tym myÅ›leÄ‡ jak o ogÃ³lenieniu $\R^n$

wÅ‚asnoÅ›ci: (dla przestrzenie liniowej `V` nad ciaÅ‚em `F`)
* dodawanie wektÃ³rÃ³w: jeÅ›li `u` i `v` sÄ… wektorami w przestrzeni liniowej `V`, to suma `u + v` takÅ¼e naleÅ¼y do `V`
* mnoÅ¼enie przez skalar: jeÅ›li `c` jest skalarem z ciaÅ‚Ä… `F`, a `v` wektorem z `V`, to `cv` rÃ³wnieÅ¼ naleÅºy do `V`
* zawieranie wektora zerowego  

przykÅ‚ady:
* $\R^n$
* $\Z_p^n$
* $\R^\R$

### podprzestrzeÅ„ liniowa
Dla przestrzeni liniowej `V` jej podzbiÃ³r` W âŠ† V` jest podprzestrzeniÄ… liniowÄ…, gdy jest przestrzeniÄ… liniowÄ… nad tym samym ciaÅ‚em i dziaÅ‚ania sÄ… okreÅ›lone tak, jak w `V`. Zapisujemy to jako `W â‰¤ V`.

### kombinacja liniowa
Kombinacja liniowa wektorÃ³w to wyraÅ¼enie utworzone przez sumÄ™ wektorÃ³w, gdzie kaÅ¼dy z wektorÃ³w jest przemnoÅ¼ony przez pewien skalar

\[
\mathbf{w} = c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 + \cdots + c_n \mathbf{v}_n
\]

### otoczka liniowa
majÄ…c wektory ze zbioru U, Otoczka liniowa to zbiÃ³r wszystkich wektorÃ³w ktÃ³re moÅ¼emy uzyskaÄ‡ przez kombinacje liniowÄ… wektorÃ³w z U. JeÅ›li chcemy przedstawiÄ‡ to graficznie np dla przestrzenie liniowej $\R^2$ to moÅ¼emy otrzymaÄ‡: punkt, linie albo wszystkie punkty w $\R^2$

Dla przestrzeni liniowej V nad ciaÅ‚em F. Dla dowolnego zbioru wektorÃ³w (skoÅ„czonego lub nie) U âŠ† V otoczka linowa, oznaczaja jako LIN(U), to zbiÃ³r wszystkich moÅ¼liwych kombinacji liniowych wektorÃ³w ze zbioru U 

$$
\text{LIN}(U) = \left\{ \sum_{i=1}^{k} \alpha_i \mathbf{v}_i \mid k \in \mathbb{N}, \alpha_1, \dots, \alpha_k \in F, \mathbf{v}_1, \dots, \mathbf{v}_k \in U \right\}.
$$

Dla dowolnego zbioru wektorÃ³w \( U \subseteq V \) w przestrzeni liniowej \( V \), otoczka liniowa \( \text{LIN}(U) \) jest podprzestrzeniÄ… liniowÄ… \( V \). Jest to najmniejsza przestrzeÅ„ liniowa zawierajÄ…ca \( U \).

Niech \( V \) bÄ™dzie przestrzeniÄ… liniowÄ…, \( U, U' \subseteq V \) ukÅ‚adami wektorÃ³w. Wtedy:

$$
\text{LIN}(U) = \text{LIN}(\text{LIN}(U)).
$$

JeÅ›li \( U \subseteq \text{LIN}(U') \) i \( U' \subseteq \text{LIN}(U) \), to

$$
\text{LIN}(U') = \text{LIN}(U).
$$


Niech \( V \) bÄ™dzie przestrzeniÄ… liniowÄ… nad ciaÅ‚em \( F \), zaÅ› \( \mathbf{v}_1, \dots, \mathbf{v}_k \in V \) wektorami z \( V \). JeÅ›li skalary \( \alpha_1, \dots, \alpha_k \in F \) sÄ… niezerowe, to:

$$
\text{LIN}(\mathbf{v}_1, \dots, \mathbf{v}_k) = \text{LIN}(\alpha_1 \mathbf{v}_1, \dots, \alpha_k \mathbf{v}_k).
$$


### liniowa nezaleÅ¼noÅ›Ä‡ wektorÃ³w

ukÅ‚ad wektorÃ³w jest liniowo niezaleÅ¼ny jeÅ›li nie istnieje taki wektor u z ukÅ‚adu ktÃ³ry moÅ¼na przedstawiÄ‡ za pomocÄ… reszty wektorÃ³w

UkÅ‚ad wektorÃ³w U âŠ† V jest liniowo zaleÅ¼ny wtedy i tylko wtedy, gdy istnieje u âˆˆ U taki Å¼e u âˆˆ LIN(U \ {~u}).

### metoda eliminacji GauBa 
wiemy ze: 
* jeÅ›li kaÅ¼dy wektor ma wspÃ³Å‚rzÄ™dnÄ…, na ktÃ³rej tylko on jest niezerowy, to zbiÃ³r jest liniowo niezaleÅ¼ny
* ukÅ‚ad wektorÃ³w zawierajÄ…cy ~0 nie jest niezaleÅ¼ny
* uÅ¼ywajÄ…c Lematu 1.23 moÅ¼emy â€upraszczaÄ‡ wektoryâ€

Po zakoÅ„czeniu eliminacji otrzymujemy ukÅ‚ad zÅ‚oÅ¼ony z wektorÃ³w liniowo niezaleÅ¼nych oraz samych wektorÃ³w zerowych. Wektory niezaleÅ¼ne rozpinajÄ… oryginalnÄ… przestrzeÅ„.

---

# rozdziaÅ‚ 2

---

### Baza przestrzeni liniowej
`def` - B jest bazÄ… przestrzeni liniowej V gdy LIN(B) = V oraz B jest liniowo niezaleÅ¼ny. Alternatywnie, mÃ³wimy, Å¼e B jest minimalnym zbiorem rozpinajÄ…cym V.

fakty:
* Eliminacja GauÃŸa zastosowana do ukÅ‚adu wektorÃ³w U zwraca bazÄ™ LIN(U) (oraz wektory zerowe).
* kaÅ¼dy wektor ma jednoznaczne przestawienie w bazie

`przedstawienie wektora w bazie` - Niech \( V \) bÄ™dzie przestrzeniÄ… wektorowÄ… nad ciaÅ‚em \( F \) i niech \( \{ \mathbf{b}_1, \mathbf{b}_2, \dots, \mathbf{b}_n \} \) bÄ™dzie bazÄ… przestrzeni \( V \). Wektor \( \mathbf{v} \in V \) moÅ¼na przedstawiÄ‡ jako kombinacjÄ™ liniowÄ… wektorÃ³w bazowych:

$$
\mathbf{v} = c_1 \mathbf{b}_1 + c_2 \mathbf{b}_2 + \cdots + c_n \mathbf{b}_n,
$$

gdzie \( c_1, c_2, \dots, c_n \in F \) sÄ… skalarami.

### izomorfizm przestrzeni liniowych 
MÃ³wimy, Å¼e dwie przestrzenie V, W nad ciaÅ‚em F sÄ… izomorficzne, jeÅ›li:
1. istniejÄ… bijekcje Ï• : V â†’ W oraz Ïˆ : W â†’ V
2. funkcje Ï• i Ïˆ zachowujÄ… dodawanie wektorÃ³w:
    dla dowolnych wektorÃ³w a i b z V: Ï•(a + b) = Ï•(a) + Ï•(b)
    dla dowolnych wektorÃ³w a i b z W: Ïˆ(a + b) = Ïˆ(a) + Ïˆ(b)
3. funkcje Ï• i Ïˆ zachowujÄ… mnoÅ¼enie wektorÃ³w:
    dla dowolnego wektora v z V i skalara c z ciaÅ‚a F: Ï•(c * v) = c * Ï•(v)
    dla dowolnego wektora w z W i skalara c z ciaÅ‚a F: Ïˆ(c * v) = c * Ïˆ(v)

Niech V nad $\mathbb{F}$ ma bazÄ™ n-elementowÄ…. Wtedy V jest izomorficzna z $\mathbb{F}^n$.
Dowolne dwie przestrzenie liniowe nad F majÄ…ce bazy n-elementowe sÄ… izomorficzne.

#### Lemat Steinitza o wymianie
Niech \( V \) bÄ™dzie przestrzeniÄ… liniowÄ…, \( A \subseteq V \) liniowo niezaleÅ¼nym ukÅ‚adem wektorÃ³w, zaÅ› \( B \) ukÅ‚adem rozpinajÄ…cym \( V \). Wtedy albo \( A \) jest bazÄ…, albo istnieje \( \mathbf{v} \in B \) taki, Å¼e \( A \cup \{\mathbf{v}\} \) jest liniowo niezaleÅ¼ny.

wnioski: KaÅ¼dy zbiÃ³r niezaleÅ¼ny skoÅ„czenie wymiarowej przestrzeni liniowej V moÅ¼na rozszerzyÄ‡ do bazy.

### Wymiar przestrzeni liniowej
Dla przestrzeni skoÅ„czenie wymiarowej V jej wymiar to moc jej bazy. Oznaczamy go jako dim(V).

Dla przestrzenie skoÅ„czonych $ V_1, V_2 \leq V$ zachodzi: 
\[ \dim(V_1 + V_2) = \dim(V_1) + \dim(V_2) - \dim(V_1 \cap V_2) \]

JeÅ›li $B_1, B_2$ sÄ… bazami dla $V_1, V_2 \leq V$ to:
$$
    V_1 + V_2 = LIN(B_1 \cup B_2)
$$

### Warstwy 
Warstwa to po prostu przesuniÄ™ta podprzestrzeÅ„ liniowa. Jest to zbiÃ³r punktÃ³w powstaÅ‚y przez dodanie ustalonego wektora do kaÅ¼dego punktu podprzestrzeni liniowej. Warstwy sÄ… podobne do podprzestrzeni, ale nie speÅ‚niajÄ… wszystkich jej wÅ‚asnoÅ›ci (na przykÅ‚ad nie przechodzÄ… przez poczÄ…tek ukÅ‚adu wspÃ³Å‚rzÄ™dnych).

Dla podprzestrzeni $W \leq V$ zachodzi:
$$
W + W = W \\
W + W = \{ w_1 + w_2: w_1, w_2 \in W \}
$$

---

# RozdziaÅ‚ 3

---

### przeksztaÅ‚cenie liniowe
Niech \( V \) i \( W \) bÄ™dÄ… przestrzeniami liniowymi nad ciaÅ‚em \( F \). Funkcja \( F : V \rightarrow W \) jest przeksztaÅ‚ceniem liniowym, jeÅ›li dla wszystkich \( \mathbf{v}, \mathbf{w} \in V \) oraz \( \alpha \in F \) speÅ‚nia:

- \( F(\alpha \mathbf{v}) = \alpha F(\mathbf{v}) \)
- \( F(\mathbf{v} + \mathbf{w}) = F(\mathbf{v}) + F(\mathbf{w}) \)

PrzeksztaÅ‚cenie liniowe nazywa siÄ™ rÃ³wnieÅ¼ **homomorfizmem** miÄ™dzy przestrzeniami \( V \) i \( W \).

ZÅ‚oÅ¼enie przeksztaÅ‚ceÅ„ liniowych jest przeksztaÅ‚ceniem liniowym.

### JÄ…dro i obraz przeksztaÅ‚cenia liniowego
dla przestrzeni liniowych \( V, W \) i przeksztaÅ‚cenia liniowego \( F : V \rightarrow W \):

`JÄ…dro przeksztaÅ‚cenia liniowego` skÅ‚ada siÄ™ z wszystkich wektorÃ³w, ktÃ³re po przeksztaÅ‚ceniu przez ğ¹ dajÄ… wektor zerowy. Jest to zbiÃ³r tych wektorÃ³w, ktÃ³re "zanikajÄ…" po przeksztaÅ‚ceniu.
$$
ker(F) = \{ \vec{v} : F( \vec{v}) = \vec{0} \}
$$

`Obraz przeksztaÅ‚cenia liiowego` to zbiÃ³r wszystkich moÅ¼liwych wynikÃ³w, jakie moÅ¼na uzyskaÄ‡ stosujÄ…c przeksztaÅ‚cenie ğ¹ do wektorÃ³w w ğ‘‰ . Oznacza to, Å¼e obraz zawiera wszystkie wektory w ğ‘Š , ktÃ³re sÄ… "osiÄ…galne" przez ğ¹.

$$
Im(F) = \{ \vec{u} : \exist \vec{v} \, \, F(\vec{v}) = \vec{u} \}
$$

JÄ…dro i obraz sÄ… przestrzeniami liniowymi

Niech $F : V \rightarrow W$ bÄ™dzie przeksztaÅ‚ceniem liniowym, gdzie $V, W$ to skoÅ„czenie wymiarowe przestrzenie liniowe:
$$
dim(V) = dim(Im(F)) + dim(ker(F))
$$

### rzÄ…d przeksztaÅ‚cenia liniowego 
RzÄ…d przeksztaÅ‚cenia liniowego $F$ to $rk(F) = dim(Im(F))$

RzÄ…d przeksztaÅ‚cenia liniowego jest liczbÄ… wymiarÃ³w przestrzeni, do ktÃ³rej przeksztaÅ‚cane sÄ… wektory z przestrzeni ğ‘‰ przez przeksztaÅ‚cenie ğ¹ . Innymi sÅ‚owy, mÃ³wi o liczbie niezaleÅ¼nych wektorÃ³w, ktÃ³re moÅ¼na uzyskaÄ‡ po przeksztaÅ‚ceniu.

JeÅ›li $F: V \rightarrow W$ jest przeksztaÅ‚ceniem liiowym i $F(\vec{v_1}), \dots, F(\vec{v_n}) \in W$ sÄ… liniowo niezaleÅºne, to rÃ³nieÅ¼ $\vec{v_1}, \dots, \vec{v_n}$ sÄ… liniowo niezaleÅºne 

---

# RozdziaÅ‚ 4

---

### macierze 
macierz identycznoÅ›ciowa:
$$
\begin{bmatrix}
1 & 0 & \dots & 0 \\
0 & 1 & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \dots & 1
\end{bmatrix}
$$

macierz gÃ³rnotrÃ³jkÄ…tna:
$$
\begin{bmatrix}
a_{11} & a_{12} & \dots & a_{1m} \\
0 & a_{2 1}& \dots & a_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \dots & a_{nm}
\end{bmatrix}
$$

##### zestawienie macierzy: 
dwie macierze M, M' rozmiaru m x n oraz m x n' (nad tym samym ciaÅ‚em) moÅ¼na zapiaÄ‡:

\[ 
\left[ M \mid M' \right] 
\]

dwie macierze M, M' rozmiaru m x n oraz m' x n moÅ¼na zapisac:

\[
\left[\frac{M}{M'}\right]
\]

MnoÅ¼enie macierzy jest Å‚Ä…czne, bo jest to funkcja, a skÅ‚adanie funkcji (w ogÃ³lnoÅ›ci: relacji) jest Å‚Ä…czne.

##### wÅ‚asnoÅ›ci macierzy:
$$
Id \, A = A \\
A(B + C) = AB + AC \\
(B + C) A = BA + CA \\
\alpha(AB) = (\alpha A ) B  = A(\alpha B) \\
A [B | C] = [AB|AC] \\
\left[\frac{B}{C}\right] A = \left[\frac{BA}{CA} \right]
$$

##### transpozycja macierzy:
$$
\begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6
\end{bmatrix}^T = 
\begin{bmatrix}
1 & 4 \\
2 & 5 \\
3 & 6
\end{bmatrix}
$$

$$
(M + N) ^ T = M^ T + N ^ T \\
(MN)^ T = N^T M^T \\
(M^T)^T = M
$$

### operacje elementarne
operacje elementarne (kolumnowe) to:
* zmiana kolumn
* dodanie do jednej z kolumn wielokrotnoÅ›ci innej
* przemnoÅ¼enie kolumny przez niezerowy skalar

(analogicznie definiujemy operacje elementarne wierszowe)

Operacje elementarne moÅ¼na przedstawiÄ‡ w postaci macierzy
Macierze odpowiadajace operacjÄ… elementarnym nazywamy **macierzami elementarnymi**

Dla macierzy M rozmiaru n x m moÅ¼emy zadaÄ‡ przeksztaÅ‚cenie liniowe $F_M : F^m \rightarrow F^n$:
$$
F_M(\vec{V}) = M \vec{V}
$$

Takie przeksztaÅ‚cenie bÄ™dziemy nazywaÄ‡ przeksztaÅ‚ceniem indukowanym przez macierz M.

##### rzÄ…d macierzy
rzÄ…d macierzy to maksymalna liczba liniowo niezaleÅ¼nych wierszy lub kolumn w tej macierzy.
Dla macierzy M i indukowanym przez niÄ… przeksztaÅ‚ceniem liniowym $F_M$ zachodzi:
$$
rk(M) = rk(F_M)
$$

RzÄ…d kolumnowy i wierszowy ustalonej macierzy M sÄ… sobie rÃ³wne, w szczegÃ³lnoÅ›ci $rk(M) = rk(M^T)$

Operacje elementarne kolumnowe (wierszowe) na macierzach nie zmieniajÄ… rzÄ™du wierszowego i kolumnowego macierzy

##### macierz odwrotna 
macierz odwrotna zapisujemy jako $M^{-1}$
$$
M \cdot M^{-1} = M^{-1} \cdot M = Id
$$

macierz jest odwracalna $\iff$ przeksztaÅ‚cenie $F_M$ jest odwracalne 

macierz M wymiaru $n \times n$ jest odwracalna $\iff rk(M) = n$  

jeÅ›li $M, N$ sÄ… odwracalne wtedy:
$$
(M^T) ^{-1} = (M^{-1})^T \\
(M^{-1})^{-1} = M
(MN)^{-1} = N^{-1}M^{-1}
$$

---

# RozdziaÅ‚ 5

---

\[
\begin{array}{ccc}
V & \xrightarrow{F} & W \\
\updownarrow (\cdot)_{\mathcal{B}_V} & & \updownarrow (\cdot)_{\mathcal{B}_W} \\
\mathbb{F}^n & \xrightarrow{M} & \mathbb{F}^m
\end{array}
\]

Diagram przemienny wizualizuje relacje miÄ™dzy przeksztaÅ‚ceniami liniowymi a ich reprezentacjami macierzowymi wzglÄ™dem wybranych baz.

1. **V i W** to przestrzenie liniowe, nad ktÃ³rymi dziaÅ‚a przeksztaÅ‚cenie liniowe \( F \).
2. **\( B_V \) i \( B_W \)** to bazy tych przestrzeni, odpowiednio \( V \) i \( W \).
3. **\( F \)** jest przeksztaÅ‚ceniem liniowym, ktÃ³re dziaÅ‚a z przestrzeni \( V \) na \( W \).
4. Macierz \( M \) to macierz przeksztaÅ‚cenia liniowego \( F \) wzglÄ™dem baz \( B_V \) i \( B_W \).

Diagram przemienny oznacza, Å¼e niezaleÅ¼nie od tego, jakÄ… drogÄ™ wybierzesz (czy najpierw zastosujesz przeksztaÅ‚cenie \( F \), a potem wyrazisz wynik w bazie \( B_W \), czy najpierw wyrazisz wektor \( V \) w bazie \( B_V \), a nastÄ™pnie pomnoÅ¼ysz go przez macierz \( M \)), wynik bÄ™dzie ten sam.

Diagram mÃ³wi nam Å¼e sÄ… dwa sposoby na przejÅ›cie z lewego gÃ³rnego rodu go prawego dolengo rogu:
$$
M_{B_V B_W}(F)(\vec{v})_{B_V} = (F \vec{v}) _ {B_W}
$$

### Macierz przeksztaÅ‚cenia w bazie
**Macierz przeksztaÅ‚cenia w bazie** to macierz, ktÃ³ra reprezentuje przeksztaÅ‚cenie liniowe \( F: V \rightarrow W \) w kontekÅ›cie wybranych baz \( B_V \) w przestrzeni \( V \) oraz \( B_W \) w przestrzeni \( W \). 

JeÅ›li \( B_V = \{ \mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n \} \) jest bazÄ… przestrzeni \( V \), a \( B_W = \{ \mathbf{w}_1, \mathbf{w}_2, \dots, \mathbf{w}_m \} \) jest bazÄ… przestrzeni \( W \), to macierz przeksztaÅ‚cenia \( M_{B_V B_W}(F) \) jest zbudowana z wektorÃ³w wspÃ³Å‚rzÄ™dnych \( F(\mathbf{v}_i) \) wyraÅ¼onych w bazie \( B_W \). 

KaÅ¼da kolumna tej macierzy odpowiada wspÃ³Å‚rzÄ™dnym wektora \( F(\mathbf{v}_i) \) w bazie \( B_W \), a macierz ma wymiary \( m \times n \), gdzie \( m \) to liczba wektorÃ³w w bazie \( B_W \), a \( n \) to liczba wektorÃ³w w bazie \( B_V \).

po ludzku: jest to macierz ktÃ³ra przyjmuje wektor v w bazie $B_V$ i zamienia go na wektor w w bazie $B_W$

### Macierz zmiany bazy
mÃ³wi nam jak przejÅ›Ä‡ w macierzy w bazie B na macierz w bazie B'
$$
M_{BB'}(\vec{v})_{B} = (\vec{v})_{B'}
$$

Niech $B_V, B'_V$ bÄ™dÄ… bazami V, Wtedy:
$$
M_{BB'}\cdot M_{B'B} = Id
$$

tzn sÄ… to macierze odwrotne

--- 

# RozdziaÅ‚ 6

---

### wyznacznik 
wyznacznik to uogÃ³lnienie objÄ™toÅ›ci (ale z znakiem) 
wyznacznik zapisujemy przez: det(M)

tutorial: https://youtu.be/wszYqnIIUr0?si=6gjb0FsZadnShJ3M

wÅ‚asnoÅ›ci:
$$
det(\vec{V_1}, \vec{V_2}, \dots, \vec{V_{i - 1}}, \vec{0}, \vec{V_{i + 1}}, \dots, \vec{V_n}) = 0 \\
JeÅ›li  \ \ \vec{V_i} = \vec{V_j} \ \ to \ \ det(\vec{V_1}, \vec{V_2}, \dots, \vec{V_n}) = 0 \\
zminana \ kolejnoÅ›ci \ dwÃ³ch \ wektorÃ³w \ zmienia \ znak \ (objÄ™tosÄ‡ \ ze \ znakiem )
$$

dla macierzy trÃ³jkÄ…tnej determinant to iloczyn elementÃ³w na przekÄ…tnej

jeÅ›li ukÅ‚ad wektorÃ³w jest liniowo zaleÅ¼ny to det jest rÃ³wny zero:
$$
det(A) \neq 0 \iff rk(A) = n 
$$

### minor 
Minorem macierzy M nazywamy kaÅ¼dÄ… macierz uzyskanÄ… poprzez usuniÄ™cie M pewnego zbioru wierszy i kolum. Zwyczjowo $A_{i, j}$ to macierz powstaÅ‚Ä… z A poprzez usuniÄ™cie i-tego wiersza oraz j-tej kolumny

### dopeÅ‚nienie algebraiczne
DopeÅ‚nienie algebraiczne elementu $a_{i, j}$ to $(-1)^{i + j} det(A_{i, j})$

### rozwiniÄ™cie laplace'a
dla macierzy kwadratowej $A = (a_{i j})_{i, j = 1, \dots, n}$ mamy:
$$
det(A) = \sum_{i = 1}^n (-1)^{i + j} \cdot a_{i,j} \cdot det(A_{i, j})
$$

po ludzku to ta normalna metoda ktÃ³ra Å¼awsze uÅ¼ywasz z wykreÅ›laniem (tutorial od 1min)

##### twierdzenie cauchy'ego
$$
det(AB) = det(A) \cdot det(B)
$$

##### waÅ¼ne wÅ‚asnoÅ›ci
$$
det(A) = det(A^T) \\
det(A) = det(A^{-1}) \\
det(A^n) = (det(A))^n \\
det(\alpha \cdot A) = \alpha ^ n \cdot det(A)
$$

jak dziaÅ‚a ta ostatnia wÅ‚asnoÅ›c:
    $c * dim(A) = dim(B)$ gdzie B to taka sama macierz jak A, ale jej jeden wierz jest przenmnoÅ¼ony przez c

### wyznacznik a macierz odwrotna
JeÅ›li M jest odwracalna, to
$$
det(M^{-1}) = \frac{1}{det(M)}
$$

niech $F : V \rightarrow V$ bÄ™dzie przeksztaÅ‚ceniem liniowym, zaÅ› M, M' bÄ™dÄ… macierzami dla tego przekstaÅ‚cenia wyraÅ¼onymi w rÃ³Å¼nych bazach. Wtedy: (wyznacznik macierzy nie zaleÅ¼y od bazy)
$$
dim(M) = dim(M')
$$

---

# RozdziaÅ‚ 7

---

wzory cramera: jeÅ›li A to macierz kwadratowa i odwracalna, to jedyne rozwiÄ…zanie jest postaci: (gdzie $A_{x_i}$ to macierz wpostaÅ‚a przez zastÄ…pienie i-tej kolumny A przez $\vec{B}$, czyli wektory wynikowy)
$$
x_i = \frac{det(A_{x_i})}{det(A)}
$$


#### ukÅ‚ad jednorodne
ukÅ‚ad postaci $\vec{B} = \vec{0}$ nazywany ukÅ‚adem jednorodnym, taki ukÅ‚ad ma na pewno jedno rozwiÄ…zanie

$$
A \vec{X} = \vec{0}
$$

#### ukÅ‚ad niejednorody
UkÅ‚ad rÃ³wnaÅ„ liniowych nazywamy niejednorodnym, jeÅ›li przynajmniej jedno z rÃ³wnaÅ„ w tym ukÅ‚adzie ma po prawej stronie rÃ³wnoÅ›ci wartoÅ›Ä‡ rÃ³Å¼nÄ… od zera. 

$$
A \vec{X} = \vec{B} \ ma \ rozwiÄ…zanie \iff \vec{B} \in Im(A)
$$
jeÅ›li rÃ³wnanie $A \vec{X} = \vec{B}$ ma rozwiÄ…zanie to zbiÃ³r wszystkich jego rozwiÄ…zaÅ„ jest warstwÄ… wzglÄ™dem ker A 

po ludzku:
* jeÅ›li B znajduje siÄ™w obrazie A, to istanieje taki wektor X, Å¼e AX = B . innymi sÅ‚owy, istnieje rozwiÄ…zanie tego rÃ³wnania
* Warstwa wzglÄ™dem ker(A) oznacza, Å¼e kaÅ¼de rowziÄ…zanie X rÃ³wnania AX = B moÅ¼na przedstawiÄ‡ jako sumÄ™ pewnego konkretnego rozwiÄ…zania $X_0$ oraz dowolengo wektora z jÄ…dara ker(A). Formalnie: X = $X_0$ + K, gdzie K $\in$ ker(A). W praktyce jeÅ›li mamy $X_0$ jedne konkretne rowsiÄ…zanie rÃ³wnania AX = B, to kaÅ¼de inne rozwiÄ…zanie X moÅ¼na uzyskaÄ‡ przez dodanie do $X_0$ dowolnego wektora K z ker(A)

##### Tw Kronecker-Capelli
ukÅ‚ad  $A \vec{X} = \vec{B} \ ma \ rozwiÄ…zanie \iff rk(A | \vec{B}) = rk(A)$

---